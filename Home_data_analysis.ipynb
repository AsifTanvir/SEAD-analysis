{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mt5864s\\AppData\\Local\\Temp\\ipykernel_21192\\3912126898.py:6: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  home_data = pd.read_csv('./Data/Home_Data/combined_sensor_dataset_latest.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of              date   time       seconds  state          sensor_name  \\\n",
      "0        08/05/23  15:26  1.691267e+09    1.0     Kitchen Humidity   \n",
      "1        08/05/23  15:26  1.691267e+09    1.0  Kitchen Temperature   \n",
      "2        08/05/23  15:27  1.691267e+09    1.0     Kitchen Humidity   \n",
      "3        08/05/23  15:30  1.691267e+09    1.0     Kitchen Humidity   \n",
      "4        08/05/23  15:31  1.691268e+09    1.0     Kitchen Humidity   \n",
      "...           ...    ...           ...    ...                  ...   \n",
      "6289486  06/20/24  07:56  1.718888e+09    0.0  Motion Outside Room   \n",
      "6289487  06/20/24  07:56  1.718888e+09    1.0  Motion Outside Room   \n",
      "6289488  06/20/24  07:56  1.718888e+09    0.0  Motion Outside Room   \n",
      "6289489  06/20/24  07:56  1.718888e+09    1.0  Motion Outside Room   \n",
      "6289490  06/20/24  07:56  1.718888e+09    0.0  Motion Outside Room   \n",
      "\n",
      "              thing_name      thing_ip thing_ip0                      datetime  \n",
      "0              KitchenPi  192.168.4.36       NaN 2023-08-05 20:26:32.866466761  \n",
      "1              KitchenPi  192.168.4.36       NaN 2023-08-05 20:26:32.866466761  \n",
      "2              KitchenPi  192.168.4.36       NaN 2023-08-05 20:27:41.995705605  \n",
      "3              KitchenPi  192.168.4.36       NaN 2023-08-05 20:30:43.212342501  \n",
      "4              KitchenPi  192.168.4.36       NaN 2023-08-05 20:31:43.626454830  \n",
      "...                  ...           ...       ...                           ...  \n",
      "6289486  BedroomClosetPi  192.168.4.33       NaN 2024-06-20 12:56:39.877210855  \n",
      "6289487  BedroomClosetPi  192.168.4.33       NaN 2024-06-20 12:56:42.691116571  \n",
      "6289488  BedroomClosetPi  192.168.4.33       NaN 2024-06-20 12:56:43.897520065  \n",
      "6289489  BedroomClosetPi  192.168.4.33       NaN 2024-06-20 12:56:46.510539054  \n",
      "6289490  BedroomClosetPi  192.168.4.33       NaN 2024-06-20 12:56:47.518497705  \n",
      "\n",
      "[6289491 rows x 9 columns]>\n",
      "['Kitchen Humidity' 'Kitchen Temperature' 'Bedroom Humidity'\n",
      " 'Motion Inside Room(West Corner)' 'Bedroom Temperature'\n",
      " 'Washroom Temperature' 'Washroom Humidity' 'Entrance Motion'\n",
      " 'Entrance Door' 'Motion Outside Room' 'Motion Inside Room(East Corner)'\n",
      " 'Room Door' 'Closet Door' 'Closet Light' 'Desk Right Sonar'\n",
      " 'Desk Right Motion' 'Desk Left Motion' 'Desk Left Sonar'\n",
      " 'Desk Left Light' 'Kitchen Light' 'Kitchen Motion' 'Washroom Door'\n",
      " 'Washroom Motion' 'Bedroom Light']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the two CSV files\n",
    "\n",
    "home_data = pd.read_csv('./Data/Home_Data/combined_sensor_dataset_latest.csv')\n",
    "# df2 = pd.read_csv('./Data/Prof_Office_Data/office_actuator_records.csv')\n",
    "\n",
    "#original_df = df1.copy() #Keep a copy to compare\n",
    "## Toggle the values of Light Sensor.\n",
    "home_data.loc[home_data['sensor_name'] == 'Light Sensor', 'state'] = 1 - home_data['state']\n",
    "\n",
    "# Change the continuous values to 1. We only need to check if the sensor is active or not\n",
    "home_data.loc[home_data['sensor_name'].isin(['Kitchen Humidity', 'Kitchen Temperature', 'Bedroom Humidity', 'Bedroom Temperature', 'Washroom Temperature', 'Washroom Humidity']), 'state'] = 1\n",
    "\n",
    "# Convert the 'datetime' column to a datetime data type if necessary\n",
    "home_data['datetime'] = pd.to_datetime(home_data['seconds'], unit='s')\n",
    "# combined_office_data['datetime'] = pd.to_datetime(combined_office_data['date'] + ' ' + combined_office_data['time'], format='%d/%m/%y %H:%M')\n",
    "\n",
    "# Sort by the 'datetime' column\n",
    "home_data = home_data.sort_values(by='datetime')\n",
    "\n",
    "# Display the sorted, combined DataFrame\n",
    "print(home_data.head)\n",
    "unique_sensor = home_data.sensor_name.unique()\n",
    "print(unique_sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def anomaly_detection_and_removal(df, timeWindow = 'h'):\n",
    "    df = df.set_index('datetime') #make the date column as index\n",
    "\n",
    "    # combined_office_data_filtered = combined_office_data.between_time('07:00', '19:00')\n",
    "    # print(combined_office_data.size, combined_office_data_filtered.size)\n",
    "    df_hourly = df.state.resample(timeWindow).sum() #resample on hourly basis and get summary of sensor values on 2 hours.\n",
    "\n",
    "    # df_hourly = df_hourly.between_time('09:00', '18:00')\n",
    "    df_hourly = df_hourly.reset_index()\n",
    "    \n",
    "    values = df_hourly[['state']]  # Selecting the 'values' column as input for the model\n",
    "\n",
    "    # Initialize and fit the IsolationForest model\n",
    "    model = IsolationForest(contamination='auto', random_state=42)\n",
    "    df_hourly['anomaly'] = model.fit_predict(values)\n",
    "\n",
    "    # Isolation Forest outputs:\n",
    "    # -1 for anomalies\n",
    "    #  1 for normal data points\n",
    "\n",
    "    # Filter the anomalies\n",
    "    # anomalies = lab_hourly[lab_hourly['anomaly'] == -1]\n",
    "    regular = df_hourly[df_hourly['anomaly'] == 1]\n",
    "    \n",
    "\n",
    "    regular_date = regular.set_index('datetime')\n",
    "    regular_idx = regular_date.index\n",
    "    # print(regular_idx)\n",
    "\n",
    "    # Filtering out the hourly anomalous data from the original data\n",
    "    filtered_df = df[df.index.floor(timeWindow).isin(regular_idx)].reset_index()\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FNE and TD implementations\n",
    "from math import ceil\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import calinski_harabasz_score, silhouette_score, davies_bouldin_score\n",
    "from neighbor_group import *\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "\n",
    "def frequent_next_event(df, adjacency_matrix):\n",
    "    prev_row = df.iloc[0]\n",
    "    for _,cur_row in df.iterrows():\n",
    "        if (cur_row.sensor_name != prev_row.sensor_name):\n",
    "            t = max(ceil(cur_row.seconds - prev_row.seconds), 1.0)\n",
    "            # t = max(ceil((cur_row.DateTime - prev_row.DateTime).total_seconds()),1.0)\n",
    "            adjacency_matrix[prev_row.sensor_name][cur_row.sensor_name] += 1/t\n",
    "        prev_row = cur_row\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "def time_delta(df, adjacency_matrix, th=2):\n",
    "    cur_group = []\n",
    "    prev_row = df.iloc[0]\n",
    "    for _, cur_row in df.iterrows():\n",
    "        if ((cur_row.seconds - prev_row.seconds) >= th):\n",
    "            cur_group = []\n",
    "        if not(cur_row.sensor_name in cur_group):\n",
    "            cur_group.append(cur_row.sensor_name)\n",
    "        for item in cur_group:\n",
    "            adjacency_matrix[item][cur_row.sensor_name] += 1\n",
    "        prev_row = cur_row\n",
    "    \n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "def get_sensor_groups(adjacency_matrix):\n",
    "    # Fixed cluster number\n",
    "    n = 2\n",
    "    max_ch = 0\n",
    "    stop_iter = 10\n",
    "    cluster_score_dict = {}\n",
    "    patience = 0\n",
    "\n",
    "    spectral_clustering = SpectralClustering(3, affinity=\"precomputed\")\n",
    "    cluster = spectral_clustering.fit_predict(adjacency_matrix)\n",
    "    embedding = SpectralEmbedding(n_components=2, affinity='precomputed')\n",
    "        \n",
    "    features = embedding.fit_transform(adjacency_matrix)\n",
    "\n",
    "    ch_score = calinski_harabasz_score(features, cluster)\n",
    "    silhouette_avg = silhouette_score(features, cluster)\n",
    "    db_score = davies_bouldin_score(features, cluster)\n",
    "\n",
    "    cluster_score_dict['cluster_number'] = 3\n",
    "    cluster_score_dict['ch-score'] = ch_score\n",
    "    cluster_score_dict['silhoutte-score'] = silhouette_avg\n",
    "    cluster_score_dict['db-score'] = db_score\n",
    "    cluster_score_dict['cluster'] = cluster\n",
    "    print(cluster_score_dict)\n",
    "\n",
    "    cluster_dict = get_cluster_sensor_list(cluster_score_dict['cluster'], adjacency_matrix)\n",
    "    adjacency_matrix_list, unique_sensors = get_adjacency_matrix_list(cluster_dict, adjacency_matrix)\n",
    "\n",
    "    # Get groups based on fixed nearest nodes\n",
    "    sensor_group = {}\n",
    "    sensor_number_each_group = 3  # Select the sensor numbers that will used to pick top nearest nodes\n",
    "    i = 1 \n",
    "    for index, matrix in enumerate(adjacency_matrix_list):\n",
    "        groups = get_groups(matrix, sensor_number_each_group, unique_sensors[index])\n",
    "        for group in groups:\n",
    "            item_list = []\n",
    "            for item in group:\n",
    "                item_list.append(item)\n",
    "            sensor_group['G'+ str(i)] = item_list\n",
    "            i += 1\n",
    "\n",
    "    # sensor_group_df = pd.DataFrame(sensor_group)\n",
    "    print(sensor_group)\n",
    "    return cluster_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent next event starts\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mt5864s\\AppData\\Local\\Temp\\ipykernel_21192\\1819911794.py:14: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  adjacency_matrix[prev_row.sensor_name][cur_row.sensor_name] += 1/t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Frequent next event ends\n",
      "Time Delta starts\n",
      "---------------------------\n",
      "---------------------------\n",
      "Time Delta ends\n",
      "{'cluster_number': 3, 'ch-score': 62.20861343866787, 'silhoutte-score': 0.7269994505079085, 'db-score': 0.29789624746318927, 'cluster': array([0, 0, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1])}\n",
      "['Kitchen Humidity', 'Kitchen Temperature', 'Entrance Motion', 'Entrance Door', 'Motion Outside Room', 'Motion Inside Room(East Corner)', 'Room Door', 'Closet Door', 'Closet Light', 'Desk Right Sonar', 'Desk Right Motion', 'Desk Left Motion', 'Desk Left Sonar', 'Desk Left Light', 'Kitchen Light', 'Kitchen Motion', 'Washroom Door', 'Washroom Motion']\n",
      "['Bedroom Humidity', 'Motion Inside Room(West Corner)', 'Bedroom Temperature', 'Bedroom Light']\n",
      "['Washroom Temperature', 'Washroom Humidity']\n",
      "number of unique group  13\n",
      "('Entrance Door', 'Entrance Motion', 'Kitchen Motion')\n",
      "('Desk Left Motion', 'Desk Left Sonar', 'Desk Right Sonar')\n",
      "('Desk Left Sonar', 'Motion Outside Room', 'Washroom Motion')\n",
      "('Desk Left Sonar', 'Kitchen Humidity', 'Kitchen Temperature')\n",
      "('Closet Door', 'Motion Inside Room(East Corner)', 'Motion Outside Room')\n",
      "('Closet Light', 'Desk Left Sonar', 'Motion Outside Room')\n",
      "('Entrance Motion', 'Kitchen Motion', 'Motion Outside Room')\n",
      "('Desk Left Motion', 'Desk Left Sonar', 'Desk Right Motion')\n",
      "('Desk Left Sonar', 'Motion Inside Room(East Corner)', 'Motion Outside Room')\n",
      "('Kitchen Light', 'Kitchen Motion', 'Motion Outside Room')\n",
      "('Motion Inside Room(East Corner)', 'Motion Outside Room', 'Room Door')\n",
      "('Motion Outside Room', 'Washroom Door', 'Washroom Motion')\n",
      "('Desk Left Light', 'Desk Left Sonar', 'Desk Right Sonar')\n",
      "number of unique group  2\n",
      "('Bedroom Humidity', 'Bedroom Temperature', 'Motion Inside Room(West Corner)')\n",
      "('Bedroom Humidity', 'Bedroom Light', 'Motion Inside Room(West Corner)')\n",
      "number of unique group  1\n",
      "('Washroom Humidity', 'Washroom Temperature')\n",
      "{'G1': ['Entrance Door', 'Entrance Motion', 'Kitchen Motion'], 'G2': ['Desk Left Motion', 'Desk Left Sonar', 'Desk Right Sonar'], 'G3': ['Desk Left Sonar', 'Motion Outside Room', 'Washroom Motion'], 'G4': ['Desk Left Sonar', 'Kitchen Humidity', 'Kitchen Temperature'], 'G5': ['Closet Door', 'Motion Inside Room(East Corner)', 'Motion Outside Room'], 'G6': ['Closet Light', 'Desk Left Sonar', 'Motion Outside Room'], 'G7': ['Entrance Motion', 'Kitchen Motion', 'Motion Outside Room'], 'G8': ['Desk Left Motion', 'Desk Left Sonar', 'Desk Right Motion'], 'G9': ['Desk Left Sonar', 'Motion Inside Room(East Corner)', 'Motion Outside Room'], 'G10': ['Kitchen Light', 'Kitchen Motion', 'Motion Outside Room'], 'G11': ['Motion Inside Room(East Corner)', 'Motion Outside Room', 'Room Door'], 'G12': ['Motion Outside Room', 'Washroom Door', 'Washroom Motion'], 'G13': ['Desk Left Light', 'Desk Left Sonar', 'Desk Right Sonar'], 'G14': ['Bedroom Humidity', 'Bedroom Temperature', 'Motion Inside Room(West Corner)'], 'G15': ['Bedroom Humidity', 'Bedroom Light', 'Motion Inside Room(West Corner)'], 'G16': ['Washroom Humidity', 'Washroom Temperature']}\n",
      "~~~ Time Delta results ~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mt5864s\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:310: UserWarning: Array is not symmetric, and will be converted to symmetric by average with its transpose.\n",
      "  adjacency = check_symmetric(adjacency)\n",
      "c:\\Users\\mt5864s\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mt5864s\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:310: UserWarning: Array is not symmetric, and will be converted to symmetric by average with its transpose.\n",
      "  adjacency = check_symmetric(adjacency)\n"
     ]
    }
   ],
   "source": [
    "unique_sensor = home_data.sensor_name.unique()\n",
    "\n",
    "fnq_adjacency_matrix = pd.DataFrame(0.0, columns=unique_sensor, index=unique_sensor)\n",
    "td_adjacency_matrix = pd.DataFrame(0.0, columns=unique_sensor, index=unique_sensor)\n",
    "\n",
    "print('Frequent next event starts')\n",
    "print('---------------------------')\n",
    "fnq_adjacency_matrix = frequent_next_event(home_data, fnq_adjacency_matrix)\n",
    "print('---------------------------')\n",
    "print('Frequent next event ends')\n",
    "\n",
    "print('Time Delta starts')\n",
    "print('---------------------------')\n",
    "# td_adjacency_matrix = time_delta(home_data, td_adjacency_matrix)\n",
    "print('---------------------------')\n",
    "print('Time Delta ends')\n",
    "\n",
    "fne_scores = get_sensor_groups(adjacency_matrix=fnq_adjacency_matrix)\n",
    "\n",
    "print(\"~~~ Time Delta results ~~~\")\n",
    "\n",
    "# td_scores = get_sensor_groups(td_adjacency_matrix)\n",
    "\n",
    "# FNE\n",
    "#{'cluster_number': 2, 'ch-score': 22.25262816159003, 'silhoutte-score': 0.6379307129426132, 'db-score': 0.4079323384378, 'cluster': array([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 1])}\n",
    "\n",
    "#TD\n",
    "#{'cluster_number': 2, 'ch-score': 23.354525308582886, 'silhoutte-score': 0.5507230369751293, 'db-score': 0.5885350572305312, 'cluster': array([1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,1, 0])}\n",
    "\n",
    "#FNE\n",
    "#{'cluster_number': 3, 'ch-score': 62.2086134386679, 'silhoutte-score': 0.7269994505079088, 'db-score': 0.29789624746318877, 'cluster': array([0, 0, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "    #    0, 1])}\n",
    "\n",
    "#TD\n",
    "# {'cluster_number': 3, 'ch-score': 50.57308549964048, 'silhoutte-score': 0.5893114768248414, 'db-score': 0.5028462040428648, 'cluster': array([0, 0, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
    "#        1, 2])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent next event starts\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mt5864s\\AppData\\Local\\Temp\\ipykernel_21192\\1819911794.py:14: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  adjacency_matrix[prev_row.sensor_name][cur_row.sensor_name] += 1/t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Frequent next event ends\n",
      "Time Delta starts\n",
      "---------------------------\n",
      "---------------------------\n",
      "Time Delta ends\n",
      "{'cluster_number': 3, 'ch-score': 43.295352171348284, 'silhoutte-score': 0.6044818314977246, 'db-score': 0.4837161590397774, 'cluster': array([2, 2, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1])}\n",
      "['Kitchen Humidity', 'Kitchen Temperature', 'Washroom Temperature', 'Washroom Humidity']\n",
      "['Bedroom Humidity', 'Motion Inside Room(West Corner)', 'Bedroom Temperature', 'Closet Light', 'Bedroom Light']\n",
      "['Entrance Motion', 'Entrance Door', 'Motion Outside Room', 'Motion Inside Room(East Corner)', 'Room Door', 'Closet Door', 'Desk Right Sonar', 'Desk Right Motion', 'Desk Left Motion', 'Desk Left Sonar', 'Desk Left Light', 'Kitchen Light', 'Kitchen Motion', 'Washroom Door', 'Washroom Motion']\n",
      "number of unique group  2\n",
      "('Kitchen Humidity', 'Kitchen Temperature', 'Washroom Humidity')\n",
      "('Kitchen Humidity', 'Washroom Humidity', 'Washroom Temperature')\n",
      "number of unique group  3\n",
      "('Bedroom Humidity', 'Bedroom Temperature', 'Motion Inside Room(West Corner)')\n",
      "('Bedroom Humidity', 'Closet Light', 'Motion Inside Room(West Corner)')\n",
      "('Bedroom Humidity', 'Bedroom Light', 'Motion Inside Room(West Corner)')\n",
      "number of unique group  13\n",
      "('Desk Left Motion', 'Desk Left Sonar', 'Desk Right Sonar')\n",
      "('Desk Left Sonar', 'Desk Right Motion', 'Desk Right Sonar')\n",
      "('Closet Door', 'Motion Inside Room(East Corner)', 'Motion Outside Room')\n",
      "('Kitchen Motion', 'Motion Outside Room', 'Washroom Motion')\n",
      "('Desk Left Motion', 'Desk Left Sonar', 'Desk Right Motion')\n",
      "('Desk Left Sonar', 'Motion Inside Room(East Corner)', 'Motion Outside Room')\n",
      "('Motion Inside Room(East Corner)', 'Motion Outside Room', 'Room Door')\n",
      "('Desk Left Light', 'Desk Left Motion', 'Desk Left Sonar')\n",
      "('Entrance Door', 'Entrance Motion', 'Motion Outside Room')\n",
      "('Kitchen Light', 'Kitchen Motion', 'Motion Outside Room')\n",
      "('Entrance Motion', 'Kitchen Motion', 'Motion Outside Room')\n",
      "('Desk Left Motion', 'Desk Right Motion', 'Motion Outside Room')\n",
      "('Motion Outside Room', 'Washroom Door', 'Washroom Motion')\n",
      "{'G1': ['Kitchen Humidity', 'Kitchen Temperature', 'Washroom Humidity'], 'G2': ['Kitchen Humidity', 'Washroom Humidity', 'Washroom Temperature'], 'G3': ['Bedroom Humidity', 'Bedroom Temperature', 'Motion Inside Room(West Corner)'], 'G4': ['Bedroom Humidity', 'Closet Light', 'Motion Inside Room(West Corner)'], 'G5': ['Bedroom Humidity', 'Bedroom Light', 'Motion Inside Room(West Corner)'], 'G6': ['Desk Left Motion', 'Desk Left Sonar', 'Desk Right Sonar'], 'G7': ['Desk Left Sonar', 'Desk Right Motion', 'Desk Right Sonar'], 'G8': ['Closet Door', 'Motion Inside Room(East Corner)', 'Motion Outside Room'], 'G9': ['Kitchen Motion', 'Motion Outside Room', 'Washroom Motion'], 'G10': ['Desk Left Motion', 'Desk Left Sonar', 'Desk Right Motion'], 'G11': ['Desk Left Sonar', 'Motion Inside Room(East Corner)', 'Motion Outside Room'], 'G12': ['Motion Inside Room(East Corner)', 'Motion Outside Room', 'Room Door'], 'G13': ['Desk Left Light', 'Desk Left Motion', 'Desk Left Sonar'], 'G14': ['Entrance Door', 'Entrance Motion', 'Motion Outside Room'], 'G15': ['Kitchen Light', 'Kitchen Motion', 'Motion Outside Room'], 'G16': ['Entrance Motion', 'Kitchen Motion', 'Motion Outside Room'], 'G17': ['Desk Left Motion', 'Desk Right Motion', 'Motion Outside Room'], 'G18': ['Motion Outside Room', 'Washroom Door', 'Washroom Motion']}\n",
      "~~~ Time Delta results ~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mt5864s\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:310: UserWarning: Array is not symmetric, and will be converted to symmetric by average with its transpose.\n",
      "  adjacency = check_symmetric(adjacency)\n",
      "c:\\Users\\mt5864s\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mt5864s\\AppData\\Local\\miniconda3\\Lib\\site-packages\\sklearn\\manifold\\_spectral_embedding.py:310: UserWarning: Array is not symmetric, and will be converted to symmetric by average with its transpose.\n",
      "  adjacency = check_symmetric(adjacency)\n"
     ]
    }
   ],
   "source": [
    "unique_sensor = home_data.sensor_name.unique()\n",
    "\n",
    "fnq_adjacency_matrix_filtered = pd.DataFrame(0.0, columns=unique_sensor, index=unique_sensor)\n",
    "td_adjacency_matrix_filtered = pd.DataFrame(0.0, columns=unique_sensor, index=unique_sensor)\n",
    "\n",
    "# filtered data after detecting and removing anomaly based on 1 hour data partition\n",
    "fd = anomaly_detection_and_removal(home_data, '4h')\n",
    "print('Frequent next event starts')\n",
    "print('---------------------------')\n",
    "fnq_adjacency_matrix_filtered = frequent_next_event(fd, fnq_adjacency_matrix_filtered)\n",
    "print('---------------------------')\n",
    "print('Frequent next event ends')\n",
    "\n",
    "print('Time Delta starts')\n",
    "print('---------------------------')\n",
    "# td_adjacency_matrix_filtered = time_delta(fd, td_adjacency_matrix_filtered)\n",
    "print('---------------------------')\n",
    "print('Time Delta ends')\n",
    "\n",
    "fne_scores_filtered = get_sensor_groups(adjacency_matrix=fnq_adjacency_matrix_filtered)\n",
    "\n",
    "print(\"~~~ Time Delta results ~~~\")\n",
    "\n",
    "# td_scores_filtered = get_sensor_groups(td_adjacency_matrix_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
